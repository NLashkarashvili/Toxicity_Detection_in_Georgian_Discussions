{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-22T21:08:14.805733Z",
     "iopub.status.busy": "2021-11-22T21:08:14.805422Z",
     "iopub.status.idle": "2021-11-22T21:08:18.538828Z",
     "shell.execute_reply": "2021-11-22T21:08:18.537886Z",
     "shell.execute_reply.started": "2021-11-22T21:08:14.805704Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import string\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T21:08:21.123930Z",
     "iopub.status.busy": "2021-11-22T21:08:21.123606Z",
     "iopub.status.idle": "2021-11-22T21:08:21.136511Z",
     "shell.execute_reply": "2021-11-22T21:08:21.135585Z",
     "shell.execute_reply.started": "2021-11-22T21:08:21.123894Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.2):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T21:08:21.138494Z",
     "iopub.status.busy": "2021-11-22T21:08:21.138218Z",
     "iopub.status.idle": "2021-11-22T21:08:21.147508Z",
     "shell.execute_reply": "2021-11-22T21:08:21.146368Z",
     "shell.execute_reply.started": "2021-11-22T21:08:21.138467Z"
    }
   },
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T21:08:21.149785Z",
     "iopub.status.busy": "2021-11-22T21:08:21.149032Z",
     "iopub.status.idle": "2021-11-22T21:08:21.160649Z",
     "shell.execute_reply": "2021-11-22T21:08:21.159810Z",
     "shell.execute_reply.started": "2021-11-22T21:08:21.149741Z"
    }
   },
   "outputs": [],
   "source": [
    "test_folds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T21:08:21.162700Z",
     "iopub.status.busy": "2021-11-22T21:08:21.162195Z",
     "iopub.status.idle": "2021-11-22T21:20:28.331154Z",
     "shell.execute_reply": "2021-11-22T21:20:28.330204Z",
     "shell.execute_reply.started": "2021-11-22T21:08:21.162661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4865 - accuracy: 0.7661 - auc: 0.8434\n",
      "Epoch 00001: val_auc improved from -inf to 0.92715, saving model to transformer_models/0001/0001.ckpt\n",
      "250/250 [==============================] - 15s 56ms/step - loss: 0.4856 - accuracy: 0.7667 - auc: 0.8438 - val_loss: 0.3338 - val_accuracy: 0.8730 - val_auc: 0.9272\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.9538 - auc: 0.9893\n",
      "Epoch 00002: val_auc did not improve from 0.92715\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.1264 - accuracy: 0.9538 - auc: 0.9893 - val_loss: 0.4271 - val_accuracy: 0.8490 - val_auc: 0.9052\n",
      "Epoch 3/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0487 - accuracy: 0.9841 - auc: 0.9977\n",
      "Epoch 00003: val_auc did not improve from 0.92715\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0485 - accuracy: 0.9841 - auc: 0.9977 - val_loss: 0.4937 - val_accuracy: 0.8790 - val_auc: 0.9159\n",
      "Epoch 4/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9885 - auc: 0.9991\n",
      "Epoch 00004: val_auc did not improve from 0.92715\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0325 - accuracy: 0.9885 - auc: 0.9991 - val_loss: 0.7766 - val_accuracy: 0.8600 - val_auc: 0.9064\n",
      "Epoch 5/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9915 - auc: 0.9988\n",
      "Epoch 00005: val_auc did not improve from 0.92715\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0278 - accuracy: 0.9915 - auc: 0.9988 - val_loss: 0.8043 - val_accuracy: 0.8790 - val_auc: 0.9003\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9915 - auc: 0.9989\n",
      "Epoch 00006: val_auc did not improve from 0.92715\n",
      "250/250 [==============================] - 13s 51ms/step - loss: 0.0274 - accuracy: 0.9915 - auc: 0.9989 - val_loss: 0.7208 - val_accuracy: 0.8760 - val_auc: 0.9012\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9918 - auc: 0.9988\n",
      "Epoch 00007: val_auc did not improve from 0.92715\n",
      "250/250 [==============================] - 13s 51ms/step - loss: 0.0262 - accuracy: 0.9918 - auc: 0.9988 - val_loss: 0.8888 - val_accuracy: 0.8530 - val_auc: 0.8890\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9942 - auc: 0.9992\n",
      "Epoch 00008: val_auc did not improve from 0.92715\n",
      "250/250 [==============================] - 13s 51ms/step - loss: 0.0192 - accuracy: 0.9942 - auc: 0.9992 - val_loss: 0.9924 - val_accuracy: 0.8720 - val_auc: 0.8949\n",
      "Epoch 9/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9933 - auc: 0.9993\n",
      "Epoch 00009: val_auc did not improve from 0.92715\n",
      "250/250 [==============================] - 13s 50ms/step - loss: 0.0190 - accuracy: 0.9934 - auc: 0.9993 - val_loss: 0.9876 - val_accuracy: 0.8700 - val_auc: 0.8916\n",
      "Epoch 10/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9955 - auc: 0.9993\n",
      "Epoch 00010: val_auc did not improve from 0.92715\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0149 - accuracy: 0.9955 - auc: 0.9993 - val_loss: 0.6841 - val_accuracy: 0.8700 - val_auc: 0.9043\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.1742 - accuracy: 0.9321 - auc: 0.9918\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.3338 - accuracy: 0.8730 - auc: 0.9272\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.3506 - accuracy: 0.8630 - auc: 0.9288\n",
      "mkdir: cannot create directory ‘model_path’: File exists\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.7516 - auc: 0.8295\n",
      "Epoch 00001: val_auc improved from -inf to 0.93858, saving model to transformer_models/0002/0001.ckpt\n",
      "250/250 [==============================] - 15s 54ms/step - loss: 0.5021 - accuracy: 0.7516 - auc: 0.8295 - val_loss: 0.2936 - val_accuracy: 0.8790 - val_auc: 0.9386\n",
      "Epoch 2/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 0.9534 - auc: 0.9892\n",
      "Epoch 00002: val_auc did not improve from 0.93858\n",
      "250/250 [==============================] - 12s 50ms/step - loss: 0.1256 - accuracy: 0.9535 - auc: 0.9893 - val_loss: 0.4158 - val_accuracy: 0.8850 - val_auc: 0.9254\n",
      "Epoch 3/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9853 - auc: 0.9980\n",
      "Epoch 00003: val_auc did not improve from 0.93858\n",
      "250/250 [==============================] - 12s 50ms/step - loss: 0.0475 - accuracy: 0.9854 - auc: 0.9980 - val_loss: 0.5459 - val_accuracy: 0.8810 - val_auc: 0.9122\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9890 - auc: 0.9984\n",
      "Epoch 00004: val_auc did not improve from 0.93858\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0363 - accuracy: 0.9890 - auc: 0.9984 - val_loss: 0.6272 - val_accuracy: 0.8890 - val_auc: 0.9228\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9908 - auc: 0.9982\n",
      "Epoch 00005: val_auc did not improve from 0.93858\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0314 - accuracy: 0.9908 - auc: 0.9982 - val_loss: 0.8216 - val_accuracy: 0.8190 - val_auc: 0.8996\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9918 - auc: 0.9988\n",
      "Epoch 00006: val_auc did not improve from 0.93858\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0276 - accuracy: 0.9918 - auc: 0.9988 - val_loss: 0.5808 - val_accuracy: 0.8610 - val_auc: 0.9132\n",
      "Epoch 7/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9923 - auc: 0.9986\n",
      "Epoch 00007: val_auc did not improve from 0.93858\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0266 - accuracy: 0.9924 - auc: 0.9986 - val_loss: 0.5635 - val_accuracy: 0.8740 - val_auc: 0.9161\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9927 - auc: 0.9994\n",
      "Epoch 00008: val_auc did not improve from 0.93858\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0212 - accuracy: 0.9927 - auc: 0.9994 - val_loss: 0.6009 - val_accuracy: 0.8820 - val_auc: 0.9196\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9935 - auc: 0.9987\n",
      "Epoch 00009: val_auc did not improve from 0.93858\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0260 - accuracy: 0.9935 - auc: 0.9987 - val_loss: 0.7418 - val_accuracy: 0.8580 - val_auc: 0.9095\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9927 - auc: 0.9988\n",
      "Epoch 00010: val_auc did not improve from 0.93858\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0239 - accuracy: 0.9927 - auc: 0.9988 - val_loss: 0.7560 - val_accuracy: 0.8880 - val_auc: 0.9172\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 0.1361 - accuracy: 0.9509 - auc: 0.9927\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.2936 - accuracy: 0.8790 - auc: 0.9386\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.2709 - accuracy: 0.9010 - auc: 0.9460\n",
      "mkdir: cannot create directory ‘model_path’: File exists\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.7656 - auc: 0.8399\n",
      "Epoch 00001: val_auc improved from -inf to 0.92096, saving model to transformer_models/0003/0001.ckpt\n",
      "250/250 [==============================] - 15s 56ms/step - loss: 0.4879 - accuracy: 0.7656 - auc: 0.8399 - val_loss: 0.3458 - val_accuracy: 0.8750 - val_auc: 0.9210\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9588 - auc: 0.9892\n",
      "Epoch 00002: val_auc did not improve from 0.92096\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.1220 - accuracy: 0.9588 - auc: 0.9892 - val_loss: 0.7261 - val_accuracy: 0.7470 - val_auc: 0.9189\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9847 - auc: 0.9978\n",
      "Epoch 00003: val_auc did not improve from 0.92096\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0475 - accuracy: 0.9847 - auc: 0.9978 - val_loss: 0.5239 - val_accuracy: 0.8670 - val_auc: 0.9208\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9879 - auc: 0.9986\n",
      "Epoch 00004: val_auc did not improve from 0.92096\n",
      "250/250 [==============================] - 13s 54ms/step - loss: 0.0372 - accuracy: 0.9879 - auc: 0.9986 - val_loss: 0.8908 - val_accuracy: 0.8500 - val_auc: 0.9032\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9912 - auc: 0.9987\n",
      "Epoch 00005: val_auc did not improve from 0.92096\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0298 - accuracy: 0.9912 - auc: 0.9987 - val_loss: 0.6836 - val_accuracy: 0.8720 - val_auc: 0.9129\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9944 - auc: 0.9992\n",
      "Epoch 00006: val_auc did not improve from 0.92096\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0180 - accuracy: 0.9944 - auc: 0.9992 - val_loss: 0.7494 - val_accuracy: 0.8660 - val_auc: 0.9072\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9927 - auc: 0.9993\n",
      "Epoch 00007: val_auc did not improve from 0.92096\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0222 - accuracy: 0.9927 - auc: 0.9993 - val_loss: 0.5096 - val_accuracy: 0.8650 - val_auc: 0.9066\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9920 - auc: 0.9993\n",
      "Epoch 00008: val_auc did not improve from 0.92096\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0248 - accuracy: 0.9920 - auc: 0.9993 - val_loss: 0.8317 - val_accuracy: 0.8720 - val_auc: 0.9079\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9930 - auc: 0.9991\n",
      "Epoch 00009: val_auc did not improve from 0.92096\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.0226 - accuracy: 0.9930 - auc: 0.9991 - val_loss: 0.7464 - val_accuracy: 0.8870 - val_auc: 0.9103\n",
      "Epoch 10/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9972 - auc: 0.9998\n",
      "Epoch 00010: val_auc did not improve from 0.92096\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0086 - accuracy: 0.9973 - auc: 0.9998 - val_loss: 1.2797 - val_accuracy: 0.8520 - val_auc: 0.8808\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.1299 - accuracy: 0.9539 - auc: 0.9916\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3458 - accuracy: 0.8750 - auc: 0.9210\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3003 - accuracy: 0.8820 - auc: 0.9386\n",
      "mkdir: cannot create directory ‘model_path’: File exists\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5060 - accuracy: 0.7575 - auc: 0.8271\n",
      "Epoch 00001: val_auc improved from -inf to 0.94408, saving model to transformer_models/0004/0001.ckpt\n",
      "250/250 [==============================] - 15s 56ms/step - loss: 0.5060 - accuracy: 0.7575 - auc: 0.8271 - val_loss: 0.2978 - val_accuracy: 0.8890 - val_auc: 0.9441\n",
      "Epoch 2/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1324 - accuracy: 0.9539 - auc: 0.9877\n",
      "Epoch 00002: val_auc improved from 0.94408 to 0.94503, saving model to transformer_models/0004/0002.ckpt\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.1326 - accuracy: 0.9539 - auc: 0.9877 - val_loss: 0.3917 - val_accuracy: 0.8650 - val_auc: 0.9450\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9861 - auc: 0.9975\n",
      "Epoch 00003: val_auc did not improve from 0.94503\n",
      "250/250 [==============================] - 13s 54ms/step - loss: 0.0515 - accuracy: 0.9861 - auc: 0.9975 - val_loss: 0.5105 - val_accuracy: 0.8870 - val_auc: 0.9265\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9914 - auc: 0.9985\n",
      "Epoch 00004: val_auc did not improve from 0.94503\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.0289 - accuracy: 0.9914 - auc: 0.9985 - val_loss: 0.5329 - val_accuracy: 0.8870 - val_auc: 0.9269\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9948 - auc: 0.9994\n",
      "Epoch 00005: val_auc did not improve from 0.94503\n",
      "250/250 [==============================] - 13s 53ms/step - loss: 0.0194 - accuracy: 0.9948 - auc: 0.9994 - val_loss: 0.3940 - val_accuracy: 0.9060 - val_auc: 0.9416\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9935 - auc: 0.9990\n",
      "Epoch 00006: val_auc did not improve from 0.94503\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.0214 - accuracy: 0.9935 - auc: 0.9990 - val_loss: 0.8097 - val_accuracy: 0.8580 - val_auc: 0.9058\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9949 - auc: 0.9994\n",
      "Epoch 00007: val_auc did not improve from 0.94503\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0179 - accuracy: 0.9949 - auc: 0.9994 - val_loss: 0.6312 - val_accuracy: 0.8930 - val_auc: 0.9206\n",
      "Epoch 8/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9920 - auc: 0.9989\n",
      "Epoch 00008: val_auc did not improve from 0.94503\n",
      "250/250 [==============================] - 13s 51ms/step - loss: 0.0252 - accuracy: 0.9919 - auc: 0.9989 - val_loss: 0.6401 - val_accuracy: 0.8960 - val_auc: 0.9224\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9934 - auc: 0.9991\n",
      "Epoch 00009: val_auc did not improve from 0.94503\n",
      "250/250 [==============================] - 14s 57ms/step - loss: 0.0201 - accuracy: 0.9934 - auc: 0.9991 - val_loss: 0.9584 - val_accuracy: 0.8720 - val_auc: 0.9163\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9927 - auc: 0.9989\n",
      "Epoch 00010: val_auc did not improve from 0.94503\n",
      "250/250 [==============================] - 13s 52ms/step - loss: 0.0263 - accuracy: 0.9927 - auc: 0.9989 - val_loss: 0.4251 - val_accuracy: 0.8930 - val_auc: 0.9331\n",
      "250/250 [==============================] - 4s 13ms/step - loss: 0.0601 - accuracy: 0.9781 - auc: 0.9990\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.3917 - accuracy: 0.8650 - auc: 0.9450\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.4306 - accuracy: 0.8440 - auc: 0.9277\n",
      "mkdir: cannot create directory ‘model_path’: File exists\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.7552 - auc: 0.8349\n",
      "Epoch 00001: val_auc improved from -inf to 0.94543, saving model to transformer_models/0005/0001.ckpt\n",
      "250/250 [==============================] - 15s 55ms/step - loss: 0.4988 - accuracy: 0.7552 - auc: 0.8349 - val_loss: 0.2928 - val_accuracy: 0.8910 - val_auc: 0.9454\n",
      "Epoch 2/10\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1469 - accuracy: 0.9492 - auc: 0.9845\n",
      "Epoch 00002: val_auc did not improve from 0.94543\n",
      "250/250 [==============================] - 13s 54ms/step - loss: 0.1469 - accuracy: 0.9491 - auc: 0.9845 - val_loss: 0.3510 - val_accuracy: 0.8680 - val_auc: 0.9379\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9776 - auc: 0.9956\n",
      "Epoch 00003: val_auc did not improve from 0.94543\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.0673 - accuracy: 0.9776 - auc: 0.9956 - val_loss: 0.4616 - val_accuracy: 0.8830 - val_auc: 0.9209\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9893 - auc: 0.9985\n",
      "Epoch 00004: val_auc did not improve from 0.94543\n",
      "250/250 [==============================] - 13s 54ms/step - loss: 0.0348 - accuracy: 0.9893 - auc: 0.9985 - val_loss: 0.5402 - val_accuracy: 0.8890 - val_auc: 0.9224\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9908 - auc: 0.9983\n",
      "Epoch 00005: val_auc did not improve from 0.94543\n",
      "250/250 [==============================] - 14s 56ms/step - loss: 0.0306 - accuracy: 0.9908 - auc: 0.9983 - val_loss: 0.8189 - val_accuracy: 0.8890 - val_auc: 0.9070\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9914 - auc: 0.9994\n",
      "Epoch 00006: val_auc did not improve from 0.94543\n",
      "250/250 [==============================] - 14s 55ms/step - loss: 0.0252 - accuracy: 0.9914 - auc: 0.9994 - val_loss: 0.6262 - val_accuracy: 0.8850 - val_auc: 0.9162\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9954 - auc: 0.9996\n",
      "Epoch 00007: val_auc did not improve from 0.94543\n",
      "250/250 [==============================] - 14s 57ms/step - loss: 0.0153 - accuracy: 0.9954 - auc: 0.9996 - val_loss: 0.8040 - val_accuracy: 0.8670 - val_auc: 0.9045\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9949 - auc: 0.9993\n",
      "Epoch 00008: val_auc did not improve from 0.94543\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0173 - accuracy: 0.9949 - auc: 0.9993 - val_loss: 0.6542 - val_accuracy: 0.8930 - val_auc: 0.9100\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9964 - auc: 0.9995\n",
      "Epoch 00009: val_auc did not improve from 0.94543\n",
      "250/250 [==============================] - 14s 54ms/step - loss: 0.0121 - accuracy: 0.9964 - auc: 0.9995 - val_loss: 1.1212 - val_accuracy: 0.8550 - val_auc: 0.8977\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9946 - auc: 0.9991\n",
      "Epoch 00010: val_auc did not improve from 0.94543\n",
      "250/250 [==============================] - 14s 57ms/step - loss: 0.0181 - accuracy: 0.9946 - auc: 0.9991 - val_loss: 1.0602 - val_accuracy: 0.8780 - val_auc: 0.8997\n",
      "250/250 [==============================] - 4s 13ms/step - loss: 0.1820 - accuracy: 0.9373 - auc: 0.9906\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.2928 - accuracy: 0.8910 - auc: 0.9454\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.3129 - accuracy: 0.8880 - auc: 0.9359\n"
     ]
    }
   ],
   "source": [
    "stfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "train_l = list()\n",
    "val_l = list()\n",
    "test_l = list()\n",
    "maxlen = 25\n",
    "cnt = 0\n",
    "for train_index, test_index in stfold.split(data['comment'], data['label']):\n",
    "    cnt += 1\n",
    "    train = data.iloc[train_index]\n",
    "    train_x, train_y = train['comment'], train['label']\n",
    "    tmp = data.iloc[test_index]\n",
    "\n",
    "    val, test = train_test_split(tmp, test_size=0.5, stratify=tmp['label'])    \n",
    "    val_x, val_y = val['comment'], val['label']\n",
    "    test_x, test_y = test['comment'], test['label']    \n",
    "    \n",
    "    train_x = keras.preprocessing.sequence.pad_sequences(train_x, maxlen=maxlen)\n",
    "    val_x = keras.preprocessing.sequence.pad_sequences(val_x, maxlen=maxlen)\n",
    "    test_x = keras.preprocessing.sequence.pad_sequences(test_x, maxlen=maxlen)\n",
    "    \n",
    "    test_folds[cnt] = (test_x, test_y)\n",
    "    embed_dim = 64  # Embedding size for each token\n",
    "    num_heads = 8  # Number of attention heads\n",
    "    ff_dim = 64  # Hidden layer size in feed forward network inside transformer\n",
    "    vocab_size = n_word_unique + 1\n",
    "\n",
    "    inputs = layers.Input(shape=(maxlen,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model_path = \"transformer_models/{itr:04}/\".format(itr=cnt)\n",
    "    checkpoint_path = model_path  + \"{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    !mkdir model_path\n",
    "    \n",
    "    model.compile(tf.keras.optimizers.Adam(lr=0.0056), \"binary_crossentropy\", metrics=[\"accuracy\", \n",
    "                                                          tf.keras.metrics.AUC(name='auc')])\n",
    "    \n",
    "    \n",
    "    #create checkpoint to save model\n",
    "    #with best validation loss\n",
    "    model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_auc', verbose=1,\n",
    "            save_weights_only=True, save_best_only=True, mode='max')\n",
    "    \n",
    "    history = model.fit(\n",
    "                        train_x, train_y, \n",
    "                        batch_size=32, epochs=10, \n",
    "                        validation_data=(val_x, val_y),\n",
    "                        callbacks = [checkpoint]\n",
    "                        )\n",
    "    \n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    model.load_weights(latest)\n",
    "    \n",
    "    train_eval = model.evaluate(train_x, train_y)\n",
    "    val_eval = model.evaluate(val_x, val_y)\n",
    "    test_eval = model.evaluate(test_x, test_y)\n",
    "    \n",
    "    test_l.append(test_eval)\n",
    "    val_l.append(val_eval)\n",
    "    train_l.append(train_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T21:20:28.335793Z",
     "iopub.status.busy": "2021-11-22T21:20:28.335465Z",
     "iopub.status.idle": "2021-11-22T21:20:28.358025Z",
     "shell.execute_reply": "2021-11-22T21:20:28.357227Z",
     "shell.execute_reply.started": "2021-11-22T21:20:28.335761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.33307995200157164 +/- 0.055080099952948644\n",
      "test avg acc:  0.875600004196167 +/- 0.019986012993357248\n",
      "test avg auc:  0.9353846073150635 +/- 0.006703173759728353\n",
      "\n",
      "\n",
      "val avg loss:  0.33153563141822817 +/- 0.036786808277246695\n",
      "val avg acc:  0.8766000032424927 +/- 0.008522896802012923\n",
      "val avg auc:  0.9354297876358032 +/- 0.009797463285738198\n",
      "\n",
      "\n",
      "train avg loss:  0.1364382289350033 +/- 0.04330184694881527\n",
      "train avg acc:  0.9504499912261963 +/- 0.01604906064639812\n",
      "train avg auc:  0.993152403831482 +/- 0.0029975613443230346\n"
     ]
    }
   ],
   "source": [
    "test_l = np.array(test_l)\n",
    "val_l = np.array(val_l)\n",
    "train_l = np.array(train_l)\n",
    "\n",
    "print(\"test avg loss: \", np.mean(test_l[:, 0]), \"+/-\" ,np.std(test_l[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(test_l[:, 1]),  \"+/-\" ,np.std(test_l[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(test_l[:, 2]),  \"+/-\" ,np.std(test_l[:, 2]))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"val avg loss: \", np.mean(val_l[:, 0]), \"+/-\" ,np.std(val_l[:, 0]))\n",
    "print(\"val avg acc: \", np.mean(val_l[:, 1]),  \"+/-\" ,np.std(val_l[:, 1]))\n",
    "print(\"val avg auc: \", np.mean(val_l[:, 2]),  \"+/-\" ,np.std(val_l[:, 2]))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"train avg loss: \", np.mean(train_l[:, 0]), \"+/-\" ,np.std(train_l[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(train_l[:, 1]),  \"+/-\" ,np.std(train_l[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(train_l[:, 2]),  \"+/-\" ,np.std(train_l[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T21:20:28.360399Z",
     "iopub.status.busy": "2021-11-22T21:20:28.359863Z",
     "iopub.status.idle": "2021-11-22T21:20:29.633228Z",
     "shell.execute_reply": "2021-11-22T21:20:29.632260Z",
     "shell.execute_reply.started": "2021-11-22T21:20:28.360359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "pred = np.array([model.predict(test_folds[5][0]) > 0.5], dtype=int).ravel()\n",
    "cm = confusion_matrix(test_folds[5][1].values, pred)\n",
    "cm = pd.DataFrame(cm, range(2),range(2))\n",
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "sns.heatmap(cm,\n",
    "            fmt = 'd',\n",
    "            annot=True)\n",
    "\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Labels')\n",
    "ax.xaxis.set_ticklabels(['non-toxic', 'toxic'])\n",
    "ax.yaxis.set_ticklabels(['non-toxic', 'toxic'])\n",
    "ax.set_title('Transformer Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T21:20:29.635229Z",
     "iopub.status.busy": "2021-11-22T21:20:29.634655Z",
     "iopub.status.idle": "2021-11-22T21:20:29.657788Z",
     "shell.execute_reply": "2021-11-22T21:20:29.656826Z",
     "shell.execute_reply.started": "2021-11-22T21:20:29.635172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('transformer.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T21:25:15.258016Z",
     "iopub.status.busy": "2021-11-22T21:25:15.257686Z",
     "iopub.status.idle": "2021-11-22T21:25:15.296199Z",
     "shell.execute_reply": "2021-11-22T21:25:15.295503Z",
     "shell.execute_reply.started": "2021-11-22T21:25:15.257987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 11.844594594594595 +/- 10.223133682642697\n",
      "incorrect 18.75 +/- 21.96660036354127\n",
      "###########################\n",
      "correct 0 11.458015267175572 +/- 11.578650850506332\n",
      "incorrect 0 25.083333333333332 +/- 35.093273982173265\n",
      "###########################\n",
      "correct 1 12.401098901098901 +/- 7.854643581113972\n",
      "incorrect 1 17.99 +/- 19.968406865027383\n"
     ]
    }
   ],
   "source": [
    "ind = np.arange(test.shape[0])\n",
    "test['word_count'] = test['comment'].apply(lambda a: len(a))\n",
    "test = test.reset_index(drop=True)\n",
    "correct = pred==test_y\n",
    "select_cor = ind[correct]\n",
    "where_0_c = ind[(correct) & (test_y==0)]\n",
    "where_0_n = ind[(correct==False) & (test_y==0)]\n",
    "where_1_c = ind[(correct) & (test_y==1)]\n",
    "where_1_n = ind[(correct==False) & (test_y==1)]\n",
    "\n",
    "cor_mean = test.iloc[select_cor]['word_count'].mean(), \n",
    "inc_mean = test.iloc[list(set(ind) - set(select_cor))]['word_count'].mean()\n",
    "cor_std = test.iloc[select_cor]['word_count'].std(), \n",
    "inc_std = test.iloc[list(set(ind) - set(select_cor))]['word_count'].std()\n",
    "print(\"correct\", cor_mean[0], '+/-', cor_std[0])\n",
    "print(\"incorrect\", inc_mean, '+/-', inc_std)\n",
    "print('###########################')\n",
    "\n",
    "cor_mean_0 = test.iloc[where_0_c]['word_count'].mean(), \n",
    "inc_mean_0 = test.iloc[where_0_n]['word_count'].mean()\n",
    "cor_std_0 = test.iloc[where_0_c]['word_count'].std(), \n",
    "inc_std_0 = test.iloc[where_0_n]['word_count'].std()\n",
    "print(\"correct 0\", cor_mean_0[0], '+/-', cor_std_0[0])\n",
    "print(\"incorrect 0\", inc_mean_0, '+/-', inc_std_0)\n",
    "print('###########################')\n",
    "\n",
    "\n",
    "cor_mean_1 = test.iloc[where_1_c]['word_count'].mean(), \n",
    "inc_mean_1 = test.iloc[where_1_n]['word_count'].mean()\n",
    "cor_std_1 = test.iloc[where_1_c]['word_count'].std(), \n",
    "inc_std_1 = test.iloc[where_1_n]['word_count'].std()\n",
    "print(\"correct 1\", cor_mean_1[0], '+/-', cor_std_1[0])\n",
    "print(\"incorrect 1\", inc_mean_1, '+/-', inc_std_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T21:25:45.584253Z",
     "iopub.status.busy": "2021-11-22T21:25:45.583932Z",
     "iopub.status.idle": "2021-11-22T21:25:45.598613Z",
     "shell.execute_reply": "2021-11-22T21:25:45.597900Z",
     "shell.execute_reply.started": "2021-11-22T21:25:45.584225Z"
    }
   },
   "outputs": [],
   "source": [
    "correct_list = list()\n",
    "incorrect_list = list()\n",
    "cor_ind = ind[correct]\n",
    "incor_ind = ind[list(set(ind) - set(select_cor))]\n",
    "for cor_com in test.iloc[cor_ind].comment:\n",
    "    correct_list.extend(cor_com)\n",
    "\n",
    "for incor_com in test.iloc[incor_ind].comment:\n",
    "    incorrect_list.extend(incor_com)\n",
    "\n",
    "cor_top10 = Counter(correct_list).most_common(10)\n",
    "incor_top10 = Counter(incorrect_list).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T21:26:16.024293Z",
     "iopub.status.busy": "2021-11-22T21:26:16.023958Z",
     "iopub.status.idle": "2021-11-22T21:26:16.037733Z",
     "shell.execute_reply": "2021-11-22T21:26:16.036834Z",
     "shell.execute_reply.started": "2021-11-22T21:26:16.024264Z"
    }
   },
   "outputs": [],
   "source": [
    "ix_to_word = {v:k for k,v in word_dict_inx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T21:26:16.977236Z",
     "iopub.status.busy": "2021-11-22T21:26:16.976917Z",
     "iopub.status.idle": "2021-11-22T21:26:16.988755Z",
     "shell.execute_reply": "2021-11-22T21:26:16.987605Z",
     "shell.execute_reply.started": "2021-11-22T21:26:16.977207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "არ\n",
      "რა\n",
      "ეს\n",
      "ჩვენი\n",
      "უნდა\n",
      "არე\n",
      "ამ\n",
      "იყო\n",
      "ვერ\n",
      "ერთი\n",
      "###################\n",
      "INCORRECT\n",
      "არ\n",
      "უნდა\n",
      "ამ\n",
      "ეს\n",
      "იყო\n",
      "რა\n",
      "არა\n",
      "საქართველო\n",
      "ის\n",
      "ჩვენი\n"
     ]
    }
   ],
   "source": [
    "print('CORRECT')\n",
    "for cor in cor_top10:\n",
    "    print(ix_to_word[cor[0]])\n",
    "print('###################')\n",
    "print('INCORRECT')\n",
    "\n",
    "for incor in incor_top10:\n",
    "    print(ix_to_word[incor[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
