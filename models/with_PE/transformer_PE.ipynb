{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T18:04:43.266857Z",
     "iopub.status.busy": "2021-08-19T18:04:43.266019Z",
     "iopub.status.idle": "2021-08-19T18:04:45.972054Z",
     "shell.execute_reply": "2021-08-19T18:04:45.971037Z",
     "shell.execute_reply.started": "2021-06-07T21:53:12.441232Z"
    },
    "papermill": {
     "duration": 2.957495,
     "end_time": "2021-08-19T18:04:45.972175",
     "exception": false,
     "start_time": "2021-08-19T18:04:43.014680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T18:07:23.133255Z",
     "iopub.status.busy": "2021-08-19T18:07:23.132532Z",
     "iopub.status.idle": "2021-08-19T18:07:23.135862Z",
     "shell.execute_reply": "2021-08-19T18:07:23.136240Z",
     "shell.execute_reply.started": "2021-06-07T21:55:37.38905Z"
    },
    "papermill": {
     "duration": 0.2207,
     "end_time": "2021-08-19T18:07:23.136371",
     "exception": false,
     "start_time": "2021-08-19T18:07:22.915671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.2):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T18:07:23.551981Z",
     "iopub.status.busy": "2021-08-19T18:07:23.550188Z",
     "iopub.status.idle": "2021-08-19T18:07:23.552557Z",
     "shell.execute_reply": "2021-08-19T18:07:23.552974Z",
     "shell.execute_reply.started": "2021-06-07T21:55:37.4016Z"
    },
    "papermill": {
     "duration": 0.215153,
     "end_time": "2021-08-19T18:07:23.553133",
     "exception": false,
     "start_time": "2021-08-19T18:07:23.337980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, emb_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb  = layers.Embedding(input_dim = vocab_size, \n",
    "                                           output_dim = emb_dim, \n",
    "                                           embeddings_initializer=keras.initializers.Constant(matrix),\n",
    "                                           trainable=True)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=emb_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T18:07:25.664124Z",
     "iopub.status.busy": "2021-08-19T18:07:25.629310Z",
     "iopub.status.idle": "2021-08-19T22:56:04.330397Z",
     "shell.execute_reply": "2021-08-19T22:56:04.330881Z"
    },
    "papermill": {
     "duration": 17318.907791,
     "end_time": "2021-08-19T22:56:04.331054",
     "exception": false,
     "start_time": "2021-08-19T18:07:25.423263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘transformer_models/0001’: No such file or directory\r\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 327s 5s/step - loss: 0.8357 - accuracy: 0.5180 - auc: 0.5238 - val_loss: 0.7864 - val_accuracy: 0.5380 - val_auc: 0.7054\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78639, saving model to transformer_models/0001-0001.ckpt\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 322s 5s/step - loss: 0.4359 - accuracy: 0.7935 - auc: 0.8792 - val_loss: 0.4540 - val_accuracy: 0.7950 - val_auc: 0.8826\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.78639 to 0.45397, saving model to transformer_models/0001-0002.ckpt\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 323s 5s/step - loss: 0.1231 - accuracy: 0.9604 - auc: 0.9903 - val_loss: 0.5656 - val_accuracy: 0.8380 - val_auc: 0.9108\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.45397\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 328s 5s/step - loss: 0.0312 - accuracy: 0.9935 - auc: 0.9987 - val_loss: 1.0799 - val_accuracy: 0.8220 - val_auc: 0.8790\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.45397\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 327s 5s/step - loss: 0.0228 - accuracy: 0.9945 - auc: 0.9988 - val_loss: 0.7142 - val_accuracy: 0.8520 - val_auc: 0.9033\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45397\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 325s 5s/step - loss: 0.0155 - accuracy: 0.9966 - auc: 0.9996 - val_loss: 0.9751 - val_accuracy: 0.8340 - val_auc: 0.8855\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45397\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 323s 5s/step - loss: 0.0069 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.0255 - val_accuracy: 0.7820 - val_auc: 0.8785\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45397\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 323s 5s/step - loss: 0.0052 - accuracy: 0.9986 - auc: 0.9999 - val_loss: 0.9571 - val_accuracy: 0.8360 - val_auc: 0.8888\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45397\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 320s 5s/step - loss: 0.0037 - accuracy: 0.9992 - auc: 0.9999 - val_loss: 1.2601 - val_accuracy: 0.8190 - val_auc: 0.8671\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45397\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 323s 5s/step - loss: 0.0043 - accuracy: 0.9990 - auc: 0.9997 - val_loss: 1.0179 - val_accuracy: 0.8600 - val_auc: 0.8903\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.45397\n",
      "250/250 [==============================] - 81s 321ms/step - loss: 0.0922 - accuracy: 0.9722 - auc: 0.9954\n",
      "32/32 [==============================] - 9s 286ms/step - loss: 0.4540 - accuracy: 0.7950 - auc: 0.8826\n",
      "32/32 [==============================] - 11s 333ms/step - loss: 0.4816 - accuracy: 0.7910 - auc: 0.8710\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 324s 5s/step - loss: 0.8895 - accuracy: 0.5244 - auc: 0.5313 - val_loss: 0.7474 - val_accuracy: 0.5480 - val_auc: 0.6344\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.74745, saving model to transformer_models/0002-0001.ckpt\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 321s 5s/step - loss: 0.5643 - accuracy: 0.7175 - auc: 0.7949 - val_loss: 1.0602 - val_accuracy: 0.4750 - val_auc: 0.8159\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.74745\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 323s 5s/step - loss: 0.1489 - accuracy: 0.9488 - auc: 0.9859 - val_loss: 0.8817 - val_accuracy: 0.6140 - val_auc: 0.8760\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.74745\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 324s 5s/step - loss: 0.0357 - accuracy: 0.9920 - auc: 0.9989 - val_loss: 0.8826 - val_accuracy: 0.7190 - val_auc: 0.8712\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.74745\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 328s 5s/step - loss: 0.0100 - accuracy: 0.9980 - auc: 0.9996 - val_loss: 0.9883 - val_accuracy: 0.8320 - val_auc: 0.8742\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.74745\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 331s 5s/step - loss: 0.0139 - accuracy: 0.9967 - auc: 0.9998 - val_loss: 0.7267 - val_accuracy: 0.8320 - val_auc: 0.8887\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.74745 to 0.72667, saving model to transformer_models/0002-0006.ckpt\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 335s 5s/step - loss: 0.0072 - accuracy: 0.9985 - auc: 1.0000 - val_loss: 1.1806 - val_accuracy: 0.8310 - val_auc: 0.8670\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.72667\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 337s 5s/step - loss: 0.0041 - accuracy: 0.9995 - auc: 0.9999 - val_loss: 1.0728 - val_accuracy: 0.8350 - val_auc: 0.8694\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.72667\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 339s 5s/step - loss: 0.0018 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 1.2481 - val_accuracy: 0.8370 - val_auc: 0.8654\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.72667\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 338s 5s/step - loss: 0.0030 - accuracy: 0.9998 - auc: 0.9999 - val_loss: 1.3086 - val_accuracy: 0.8300 - val_auc: 0.8682\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.72667\n",
      "250/250 [==============================] - 82s 326ms/step - loss: 0.0060 - accuracy: 0.9983 - auc: 1.0000\n",
      "32/32 [==============================] - 10s 299ms/step - loss: 0.7267 - accuracy: 0.8320 - auc: 0.8887\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.6519 - accuracy: 0.8340 - auc: 0.9023\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 340s 5s/step - loss: 0.8741 - accuracy: 0.5192 - auc: 0.5084 - val_loss: 0.6841 - val_accuracy: 0.5340 - val_auc: 0.6176\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68406, saving model to transformer_models/0003-0001.ckpt\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 338s 5s/step - loss: 0.6691 - accuracy: 0.6176 - auc: 0.6678 - val_loss: 0.6282 - val_accuracy: 0.6190 - val_auc: 0.7974\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68406 to 0.62821, saving model to transformer_models/0003-0002.ckpt\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 339s 5s/step - loss: 0.2133 - accuracy: 0.9275 - auc: 0.9734 - val_loss: 0.4653 - val_accuracy: 0.7850 - val_auc: 0.8963\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62821 to 0.46526, saving model to transformer_models/0003-0003.ckpt\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 340s 5s/step - loss: 0.0597 - accuracy: 0.9830 - auc: 0.9967 - val_loss: 0.7164 - val_accuracy: 0.8450 - val_auc: 0.9018\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.46526\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 339s 5s/step - loss: 0.0215 - accuracy: 0.9954 - auc: 0.9994 - val_loss: 0.5391 - val_accuracy: 0.8340 - val_auc: 0.9069\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.46526\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 335s 5s/step - loss: 0.0109 - accuracy: 0.9983 - auc: 0.9999 - val_loss: 0.7193 - val_accuracy: 0.8250 - val_auc: 0.9046\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.46526\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 338s 5s/step - loss: 0.0062 - accuracy: 0.9991 - auc: 0.9998 - val_loss: 0.9010 - val_accuracy: 0.8580 - val_auc: 0.8963\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.46526\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 336s 5s/step - loss: 0.0053 - accuracy: 0.9992 - auc: 0.9999 - val_loss: 0.7680 - val_accuracy: 0.8450 - val_auc: 0.9026\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.46526\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 341s 5s/step - loss: 0.0050 - accuracy: 0.9995 - auc: 0.9996 - val_loss: 0.6878 - val_accuracy: 0.8580 - val_auc: 0.9075\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.46526\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 343s 5s/step - loss: 0.0032 - accuracy: 0.9995 - auc: 0.9999 - val_loss: 1.0983 - val_accuracy: 0.7820 - val_auc: 0.8787\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.46526\n",
      "250/250 [==============================] - 79s 316ms/step - loss: 0.1194 - accuracy: 0.9833 - auc: 0.9988\n",
      "32/32 [==============================] - 10s 328ms/step - loss: 0.4653 - accuracy: 0.7850 - auc: 0.8963\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 0.4741 - accuracy: 0.7770 - auc: 0.8971\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 338s 5s/step - loss: 0.8967 - accuracy: 0.5120 - auc: 0.5151 - val_loss: 0.7839 - val_accuracy: 0.5350 - val_auc: 0.6500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78395, saving model to transformer_models/0004-0001.ckpt\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 338s 5s/step - loss: 0.5317 - accuracy: 0.7364 - auc: 0.8134 - val_loss: 0.6256 - val_accuracy: 0.5990 - val_auc: 0.8562\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.78395 to 0.62564, saving model to transformer_models/0004-0002.ckpt\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 334s 5s/step - loss: 0.1275 - accuracy: 0.9570 - auc: 0.9897 - val_loss: 0.5899 - val_accuracy: 0.8570 - val_auc: 0.9004\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62564 to 0.58990, saving model to transformer_models/0004-0003.ckpt\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 336s 5s/step - loss: 0.0305 - accuracy: 0.9923 - auc: 0.9991 - val_loss: 1.0418 - val_accuracy: 0.7330 - val_auc: 0.8781\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.58990\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 337s 5s/step - loss: 0.0125 - accuracy: 0.9969 - auc: 0.9997 - val_loss: 0.9517 - val_accuracy: 0.8620 - val_auc: 0.8981\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.58990\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 335s 5s/step - loss: 0.0104 - accuracy: 0.9976 - auc: 0.9997 - val_loss: 1.6767 - val_accuracy: 0.7580 - val_auc: 0.8413\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.58990\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 334s 5s/step - loss: 0.0273 - accuracy: 0.9939 - auc: 0.9989 - val_loss: 0.4433 - val_accuracy: 0.8610 - val_auc: 0.9145\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.58990 to 0.44326, saving model to transformer_models/0004-0007.ckpt\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 334s 5s/step - loss: 0.0093 - accuracy: 0.9985 - auc: 0.9998 - val_loss: 0.7205 - val_accuracy: 0.8580 - val_auc: 0.9048\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44326\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 335s 5s/step - loss: 0.0053 - accuracy: 0.9989 - auc: 1.0000 - val_loss: 1.1456 - val_accuracy: 0.8550 - val_auc: 0.8881\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44326\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 333s 5s/step - loss: 0.0051 - accuracy: 0.9990 - auc: 0.9997 - val_loss: 1.0974 - val_accuracy: 0.8550 - val_auc: 0.8834\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44326\n",
      "250/250 [==============================] - 80s 320ms/step - loss: 0.0084 - accuracy: 0.9985 - auc: 1.0000\n",
      "32/32 [==============================] - 9s 289ms/step - loss: 0.4433 - accuracy: 0.8610 - auc: 0.9145\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 0.4638 - accuracy: 0.8380 - auc: 0.9174\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 335s 5s/step - loss: 0.8950 - accuracy: 0.5235 - auc: 0.5127 - val_loss: 1.3112 - val_accuracy: 0.5360 - val_auc: 0.6335\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.31124, saving model to transformer_models/0005-0001.ckpt\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 336s 5s/step - loss: 0.5223 - accuracy: 0.7356 - auc: 0.8180 - val_loss: 0.5469 - val_accuracy: 0.7200 - val_auc: 0.8428\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.31124 to 0.54692, saving model to transformer_models/0005-0002.ckpt\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 342s 5s/step - loss: 0.1291 - accuracy: 0.9556 - auc: 0.9893 - val_loss: 0.5397 - val_accuracy: 0.7850 - val_auc: 0.8944\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.54692 to 0.53975, saving model to transformer_models/0005-0003.ckpt\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 345s 5s/step - loss: 0.0371 - accuracy: 0.9912 - auc: 0.9989 - val_loss: 0.6771 - val_accuracy: 0.8490 - val_auc: 0.8915\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.53975\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 345s 5s/step - loss: 0.0163 - accuracy: 0.9969 - auc: 0.9997 - val_loss: 1.0160 - val_accuracy: 0.8370 - val_auc: 0.8829\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.53975\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 340s 5s/step - loss: 0.0077 - accuracy: 0.9986 - auc: 0.9996 - val_loss: 1.0344 - val_accuracy: 0.8140 - val_auc: 0.8718\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.53975\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 340s 5s/step - loss: 0.0095 - accuracy: 0.9983 - auc: 0.9994 - val_loss: 0.9100 - val_accuracy: 0.8330 - val_auc: 0.8810\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.53975\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 340s 5s/step - loss: 0.0056 - accuracy: 0.9992 - auc: 0.9997 - val_loss: 0.9169 - val_accuracy: 0.8340 - val_auc: 0.8829\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.53975\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 340s 5s/step - loss: 0.0062 - accuracy: 0.9987 - auc: 0.9998 - val_loss: 1.1263 - val_accuracy: 0.8230 - val_auc: 0.8739\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.53975\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 340s 5s/step - loss: 0.0042 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 1.6733 - val_accuracy: 0.8160 - val_auc: 0.8329\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.53975\n",
      "250/250 [==============================] - 81s 323ms/step - loss: 0.0238 - accuracy: 0.9939 - auc: 0.9994\n",
      "32/32 [==============================] - 9s 294ms/step - loss: 0.5397 - accuracy: 0.7850 - auc: 0.8944\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 0.4971 - accuracy: 0.8160 - auc: 0.9049\n"
     ]
    }
   ],
   "source": [
    "stfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "train_l = list()\n",
    "val_l = list()\n",
    "test_l = list()\n",
    "maxlen = 100\n",
    "num_heads = 8\n",
    "ff_dim = 32 \n",
    "\n",
    "cnt = 0\n",
    "for train_index, test_index in stfold.split(data['comment'], data['label']):\n",
    "    cnt += 1\n",
    "    train = data.iloc[train_index]\n",
    "    train_x, train_y = train['comment'], train['label']\n",
    "    tmp = data.iloc[test_index]\n",
    "\n",
    "    val, test = train_test_split(tmp, test_size=0.5, stratify=tmp['label'])    \n",
    "    val_x, val_y = val['comment'], val['label']\n",
    "    test_x, test_y = test['comment'], test['label']    \n",
    "    \n",
    "    train_x = vectorizer(np.array([[s] for s in train_x])).numpy()    \n",
    "    val_x = vectorizer(np.array([[s] for s in val_x])).numpy()\n",
    "    test_x = vectorizer(np.array([[s] for s in test_x])).numpy()\n",
    "\n",
    "    train_x = keras.preprocessing.sequence.pad_sequences(train_x, maxlen=maxlen)\n",
    "    val_x = keras.preprocessing.sequence.pad_sequences(val_x, maxlen=maxlen)\n",
    "    test_x = keras.preprocessing.sequence.pad_sequences(test_x, maxlen=maxlen)\n",
    "    \n",
    "\n",
    "    inputs = layers.Input(shape=(maxlen,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, emb_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(emb_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(20, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model_path = \"transformer_models/{itr:04}\".format(itr=cnt)\n",
    "    checkpoint_path = model_path + \"-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    !mkdir $model_path\n",
    "    \n",
    "    model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\", \n",
    "                                                          tf.keras.metrics.AUC(name='auc')])\n",
    "    \n",
    "  \n",
    "    #create checkpoint to save model\n",
    "    #with best validation loss\n",
    "    model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1,\n",
    "            save_weights_only=True, save_best_only=True, mode='auto')\n",
    "    \n",
    "    history = model.fit(\n",
    "                        train_x, train_y, \n",
    "                        batch_size=128, epochs=10, \n",
    "                        validation_data=(val_x, val_y),\n",
    "                        callbacks = [checkpoint]\n",
    "                        )\n",
    "    \n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    model.load_weights(latest)\n",
    "    \n",
    "    train_eval = model.evaluate(train_x, train_y)\n",
    "    val_eval = model.evaluate(val_x, val_y)\n",
    "    test_eval = model.evaluate(test_x, test_y)\n",
    "    \n",
    "    test_l.append(test_eval)\n",
    "    val_l.append(val_eval)\n",
    "    train_l.append(train_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T22:56:07.458264Z",
     "iopub.status.busy": "2021-08-19T22:56:07.457124Z",
     "iopub.status.idle": "2021-08-19T22:56:07.467492Z",
     "shell.execute_reply": "2021-08-19T22:56:07.468034Z"
    },
    "papermill": {
     "duration": 1.552858,
     "end_time": "2021-08-19T22:56:07.468168",
     "exception": false,
     "start_time": "2021-08-19T22:56:05.915310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.5136931657791137 +/- 0.06994241723575245\n",
      "test avg acc:  0.8111999988555908 +/- 0.02382770826111824\n",
      "test avg auc:  0.8985428810119629 +/- 0.015285996380062995\n",
      "\n",
      "\n",
      "val avg loss:  0.5257814049720764 +/- 0.10599973988018306\n",
      "val avg acc:  0.8116000175476075 +/- 0.030156914620622366\n",
      "val avg auc:  0.8952931880950927 +/- 0.010714450573773621\n",
      "\n",
      "\n",
      "train avg loss:  0.049974911380559206 +/- 0.04680226783502984\n",
      "train avg acc:  0.9892250061035156 +/- 0.010128676590453767\n",
      "train avg auc:  0.9987109541893006 +/- 0.0017073192278102673\n"
     ]
    }
   ],
   "source": [
    "test_l = np.array(test_l)\n",
    "val_l = np.array(val_l)\n",
    "train_l = np.array(train_l)\n",
    "\n",
    "print(\"test avg loss: \", np.mean(test_l[:, 0]), \"+/-\" ,np.std(test_l[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(test_l[:, 1]),  \"+/-\" ,np.std(test_l[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(test_l[:, 2]),  \"+/-\" ,np.std(test_l[:, 2]))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"val avg loss: \", np.mean(val_l[:, 0]), \"+/-\" ,np.std(val_l[:, 0]))\n",
    "print(\"val avg acc: \", np.mean(val_l[:, 1]),  \"+/-\" ,np.std(val_l[:, 1]))\n",
    "print(\"val avg auc: \", np.mean(val_l[:, 2]),  \"+/-\" ,np.std(val_l[:, 2]))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"train avg loss: \", np.mean(train_l[:, 0]), \"+/-\" ,np.std(train_l[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(train_l[:, 1]),  \"+/-\" ,np.std(train_l[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(train_l[:, 2]),  \"+/-\" ,np.std(train_l[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 17585.328929,
   "end_time": "2021-08-19T22:56:09.414165",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-19T18:03:04.085236",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
