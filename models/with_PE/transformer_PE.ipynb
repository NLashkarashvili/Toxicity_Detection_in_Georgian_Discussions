{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T22:19:37.147291Z",
     "iopub.status.busy": "2021-08-28T22:19:37.146661Z",
     "iopub.status.idle": "2021-08-28T22:19:40.249370Z",
     "shell.execute_reply": "2021-08-28T22:19:40.248302Z",
     "shell.execute_reply.started": "2021-08-28T13:31:43.270303Z"
    },
    "papermill": {
     "duration": 3.337615,
     "end_time": "2021-08-28T22:19:40.249502",
     "exception": false,
     "start_time": "2021-08-28T22:19:36.911887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from gensim import models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T22:22:18.426873Z",
     "iopub.status.busy": "2021-08-28T22:22:18.426076Z",
     "iopub.status.idle": "2021-08-28T22:22:18.429348Z",
     "shell.execute_reply": "2021-08-28T22:22:18.428805Z",
     "shell.execute_reply.started": "2021-08-28T13:34:17.844905Z"
    },
    "papermill": {
     "duration": 0.267595,
     "end_time": "2021-08-28T22:22:18.429462",
     "exception": false,
     "start_time": "2021-08-28T22:22:18.161867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.2):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T22:22:18.887097Z",
     "iopub.status.busy": "2021-08-28T22:22:18.886527Z",
     "iopub.status.idle": "2021-08-28T22:22:18.890556Z",
     "shell.execute_reply": "2021-08-28T22:22:18.889878Z",
     "shell.execute_reply.started": "2021-08-28T13:34:17.857847Z"
    },
    "papermill": {
     "duration": 0.237448,
     "end_time": "2021-08-28T22:22:18.890653",
     "exception": false,
     "start_time": "2021-08-28T22:22:18.653205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, emb_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb  = layers.Embedding(input_dim = vocab_size, \n",
    "                                           output_dim = emb_dim, \n",
    "                                           embeddings_initializer=keras.initializers.Constant(matrix),\n",
    "                                           trainable=True)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=emb_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T22:22:21.134296Z",
     "iopub.status.busy": "2021-08-28T22:22:21.133445Z",
     "iopub.status.idle": "2021-08-29T03:04:31.185476Z",
     "shell.execute_reply": "2021-08-29T03:04:31.184933Z",
     "shell.execute_reply.started": "2021-08-28T22:10:16.353749Z"
    },
    "papermill": {
     "duration": 16930.315026,
     "end_time": "2021-08-29T03:04:31.185599",
     "exception": false,
     "start_time": "2021-08-28T22:22:20.870573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘transformer_models/0001’: No such file or directory\r\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 314s 5s/step - loss: 0.8479 - accuracy: 0.5278 - auc: 0.5344 - val_loss: 0.6527 - val_accuracy: 0.5890 - val_auc: 0.7093\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.70928, saving model to transformer_models/0001-0001.ckpt\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 314s 5s/step - loss: 0.2952 - accuracy: 0.8754 - auc: 0.9470 - val_loss: 3.1895 - val_accuracy: 0.4640 - val_auc: 0.6212\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.70928\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 316s 5s/step - loss: 0.0937 - accuracy: 0.9694 - auc: 0.9936 - val_loss: 0.5208 - val_accuracy: 0.8060 - val_auc: 0.8935\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.70928 to 0.89350, saving model to transformer_models/0001-0003.ckpt\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 319s 5s/step - loss: 0.0272 - accuracy: 0.9916 - auc: 0.9988 - val_loss: 0.4948 - val_accuracy: 0.8430 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.89350 to 0.90454, saving model to transformer_models/0001-0004.ckpt\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 321s 5s/step - loss: 0.0063 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.8490 - val_accuracy: 0.7920 - val_auc: 0.8850\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.90454\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 321s 5s/step - loss: 0.0041 - accuracy: 0.9992 - auc: 0.9998 - val_loss: 0.8506 - val_accuracy: 0.8440 - val_auc: 0.8898\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.90454\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 318s 5s/step - loss: 0.0019 - accuracy: 0.9996 - auc: 0.9999 - val_loss: 1.0109 - val_accuracy: 0.8440 - val_auc: 0.8835\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.90454\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 317s 5s/step - loss: 0.0027 - accuracy: 0.9995 - auc: 0.9998 - val_loss: 1.0189 - val_accuracy: 0.8330 - val_auc: 0.8741\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.90454\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 318s 5s/step - loss: 0.0024 - accuracy: 0.9996 - auc: 0.9999 - val_loss: 1.8049 - val_accuracy: 0.6300 - val_auc: 0.8279\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.90454\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 317s 5s/step - loss: 0.0035 - accuracy: 0.9992 - auc: 1.0000 - val_loss: 1.3662 - val_accuracy: 0.6550 - val_auc: 0.8570\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.90454\n",
      "250/250 [==============================] - 78s 310ms/step - loss: 0.0050 - accuracy: 0.9992 - auc: 1.0000\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 0.4948 - accuracy: 0.8430 - auc: 0.9045\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.4801 - accuracy: 0.8520 - auc: 0.9095\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 317s 5s/step - loss: 0.8125 - accuracy: 0.5530 - auc: 0.5733 - val_loss: 0.7031 - val_accuracy: 0.4990 - val_auc: 0.7999\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.79990, saving model to transformer_models/0002-0001.ckpt\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 317s 5s/step - loss: 0.2244 - accuracy: 0.9133 - auc: 0.9693 - val_loss: 0.6571 - val_accuracy: 0.7160 - val_auc: 0.8979\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.79990 to 0.89789, saving model to transformer_models/0002-0002.ckpt\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 320s 5s/step - loss: 0.0654 - accuracy: 0.9794 - auc: 0.9964 - val_loss: 0.4158 - val_accuracy: 0.8320 - val_auc: 0.9125\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.89789 to 0.91247, saving model to transformer_models/0002-0003.ckpt\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 324s 5s/step - loss: 0.0189 - accuracy: 0.9942 - auc: 0.9995 - val_loss: 0.8595 - val_accuracy: 0.8350 - val_auc: 0.8957\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.91247\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 329s 5s/step - loss: 0.0095 - accuracy: 0.9976 - auc: 0.9998 - val_loss: 0.5983 - val_accuracy: 0.8140 - val_auc: 0.9080\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.91247\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 325s 5s/step - loss: 0.0028 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.8110 - val_auc: 0.8965\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.91247\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 320s 5s/step - loss: 0.0042 - accuracy: 0.9994 - auc: 0.9997 - val_loss: 1.1044 - val_accuracy: 0.8430 - val_auc: 0.8849\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.91247\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 321s 5s/step - loss: 0.0029 - accuracy: 0.9996 - auc: 0.9999 - val_loss: 0.5893 - val_accuracy: 0.8480 - val_auc: 0.9103\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.91247\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 324s 5s/step - loss: 0.0024 - accuracy: 0.9995 - auc: 0.9999 - val_loss: 0.6650 - val_accuracy: 0.8640 - val_auc: 0.9091\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.91247\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 323s 5s/step - loss: 0.0013 - accuracy: 0.9998 - auc: 0.9999 - val_loss: 0.8347 - val_accuracy: 0.8590 - val_auc: 0.9004\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.91247\n",
      "250/250 [==============================] - 75s 297ms/step - loss: 0.0190 - accuracy: 0.9966 - auc: 0.9997\n",
      "32/32 [==============================] - 10s 306ms/step - loss: 0.4158 - accuracy: 0.8320 - auc: 0.9125\n",
      "32/32 [==============================] - 10s 296ms/step - loss: 0.4252 - accuracy: 0.8540 - auc: 0.9145\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 326s 5s/step - loss: 0.7970 - accuracy: 0.5642 - auc: 0.5797 - val_loss: 0.9316 - val_accuracy: 0.5540 - val_auc: 0.7838\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.78383, saving model to transformer_models/0003-0001.ckpt\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 331s 5s/step - loss: 0.2146 - accuracy: 0.9162 - auc: 0.9721 - val_loss: 1.4681 - val_accuracy: 0.6640 - val_auc: 0.8398\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.78383 to 0.83975, saving model to transformer_models/0003-0002.ckpt\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 331s 5s/step - loss: 0.0791 - accuracy: 0.9758 - auc: 0.9946 - val_loss: 0.5822 - val_accuracy: 0.8290 - val_auc: 0.8982\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.83975 to 0.89817, saving model to transformer_models/0003-0003.ckpt\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 330s 5s/step - loss: 0.0152 - accuracy: 0.9948 - auc: 0.9998 - val_loss: 0.7100 - val_accuracy: 0.8110 - val_auc: 0.8894\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.89817\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 328s 5s/step - loss: 0.0067 - accuracy: 0.9985 - auc: 0.9998 - val_loss: 0.9866 - val_accuracy: 0.8190 - val_auc: 0.8756\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.89817\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 324s 5s/step - loss: 0.0043 - accuracy: 0.9991 - auc: 0.9997 - val_loss: 1.5562 - val_accuracy: 0.7720 - val_auc: 0.8361\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.89817\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 326s 5s/step - loss: 0.0045 - accuracy: 0.9987 - auc: 1.0000 - val_loss: 1.5083 - val_accuracy: 0.6130 - val_auc: 0.8430\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.89817\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 325s 5s/step - loss: 0.0065 - accuracy: 0.9986 - auc: 0.9997 - val_loss: 0.6704 - val_accuracy: 0.8310 - val_auc: 0.8920\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.89817\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 331s 5s/step - loss: 0.0018 - accuracy: 0.9996 - auc: 0.9999 - val_loss: 0.7533 - val_accuracy: 0.8350 - val_auc: 0.8920\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.89817\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 337s 5s/step - loss: 0.0011 - accuracy: 0.9996 - auc: 1.0000 - val_loss: 0.8479 - val_accuracy: 0.8330 - val_auc: 0.8888\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.89817\n",
      "250/250 [==============================] - 81s 324ms/step - loss: 0.0140 - accuracy: 0.9961 - auc: 0.9999\n",
      "32/32 [==============================] - 10s 299ms/step - loss: 0.5822 - accuracy: 0.8290 - auc: 0.8982\n",
      "32/32 [==============================] - 11s 331ms/step - loss: 0.5753 - accuracy: 0.8360 - auc: 0.9036\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 337s 5s/step - loss: 0.8153 - accuracy: 0.5495 - auc: 0.5611 - val_loss: 0.6170 - val_accuracy: 0.6630 - val_auc: 0.7810\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.78102, saving model to transformer_models/0004-0001.ckpt\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 337s 5s/step - loss: 0.2407 - accuracy: 0.9045 - auc: 0.9649 - val_loss: 0.5766 - val_accuracy: 0.7520 - val_auc: 0.8638\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.78102 to 0.86376, saving model to transformer_models/0004-0002.ckpt\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 338s 5s/step - loss: 0.0866 - accuracy: 0.9719 - auc: 0.9939 - val_loss: 0.5171 - val_accuracy: 0.8000 - val_auc: 0.8938\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.86376 to 0.89384, saving model to transformer_models/0004-0003.ckpt\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 332s 5s/step - loss: 0.0215 - accuracy: 0.9936 - auc: 0.9994 - val_loss: 0.5427 - val_accuracy: 0.8450 - val_auc: 0.8930\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.89384\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 332s 5s/step - loss: 0.0052 - accuracy: 0.9992 - auc: 1.0000 - val_loss: 1.1699 - val_accuracy: 0.8250 - val_auc: 0.8749\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.89384\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 333s 5s/step - loss: 0.0023 - accuracy: 0.9996 - auc: 0.9999 - val_loss: 1.0868 - val_accuracy: 0.8470 - val_auc: 0.8836\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.89384\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 332s 5s/step - loss: 8.2756e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 1.6629 - val_accuracy: 0.8070 - val_auc: 0.8492\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.89384\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 330s 5s/step - loss: 3.0457e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.9433 - val_accuracy: 0.8520 - val_auc: 0.8896\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.89384\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 333s 5s/step - loss: 8.2627e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.0448 - val_accuracy: 0.8530 - val_auc: 0.8881\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.89384\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 328s 5s/step - loss: 4.9552e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.0008 - val_accuracy: 0.8500 - val_auc: 0.8875\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.89384\n",
      "250/250 [==============================] - 78s 311ms/step - loss: 0.0272 - accuracy: 0.9942 - auc: 0.9997\n",
      "32/32 [==============================] - 9s 277ms/step - loss: 0.5171 - accuracy: 0.8000 - auc: 0.8938\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.4848 - accuracy: 0.8130 - auc: 0.9035\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 333s 5s/step - loss: 0.7990 - accuracy: 0.5493 - auc: 0.5679 - val_loss: 1.9415 - val_accuracy: 0.5360 - val_auc: 0.7629\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.76286, saving model to transformer_models/0005-0001.ckpt\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 330s 5s/step - loss: 0.2255 - accuracy: 0.9089 - auc: 0.9687 - val_loss: 4.9620 - val_accuracy: 0.4650 - val_auc: 0.5047\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.76286\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 326s 5s/step - loss: 0.0746 - accuracy: 0.9765 - auc: 0.9956 - val_loss: 1.6699 - val_accuracy: 0.5250 - val_auc: 0.8590\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.76286 to 0.85900, saving model to transformer_models/0005-0003.ckpt\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 325s 5s/step - loss: 0.0211 - accuracy: 0.9939 - auc: 0.9992 - val_loss: 0.7766 - val_accuracy: 0.8450 - val_auc: 0.8933\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.85900 to 0.89325, saving model to transformer_models/0005-0004.ckpt\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 324s 5s/step - loss: 0.0054 - accuracy: 0.9986 - auc: 0.9998 - val_loss: 1.2904 - val_accuracy: 0.8070 - val_auc: 0.8636\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.89325\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 324s 5s/step - loss: 0.0060 - accuracy: 0.9987 - auc: 0.9997 - val_loss: 1.1624 - val_accuracy: 0.8300 - val_auc: 0.8771\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.89325\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 324s 5s/step - loss: 0.0038 - accuracy: 0.9992 - auc: 0.9999 - val_loss: 0.8605 - val_accuracy: 0.8470 - val_auc: 0.8870\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.89325\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 324s 5s/step - loss: 0.0042 - accuracy: 0.9991 - auc: 0.9997 - val_loss: 0.6556 - val_accuracy: 0.8440 - val_auc: 0.9049\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.89325 to 0.90494, saving model to transformer_models/0005-0008.ckpt\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 326s 5s/step - loss: 0.0045 - accuracy: 0.9989 - auc: 1.0000 - val_loss: 0.6117 - val_accuracy: 0.8410 - val_auc: 0.9032\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.90494\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 325s 5s/step - loss: 0.0030 - accuracy: 0.9991 - auc: 1.0000 - val_loss: 0.9043 - val_accuracy: 0.8110 - val_auc: 0.8889\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.90494\n",
      "250/250 [==============================] - 76s 301ms/step - loss: 7.9801e-04 - accuracy: 0.9996 - auc: 1.0000\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.6556 - accuracy: 0.8440 - auc: 0.9049\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 0.5513 - accuracy: 0.8600 - auc: 0.9158\n"
     ]
    }
   ],
   "source": [
    "stfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "train_l = list()\n",
    "val_l = list()\n",
    "test_l = list()\n",
    "maxlen = 100\n",
    "num_heads = 8\n",
    "ff_dim = 32 \n",
    "\n",
    "cnt = 0\n",
    "for train_index, test_index in stfold.split(data['comment'], data['label']):\n",
    "    cnt += 1\n",
    "    train = data.iloc[train_index]\n",
    "    train_x, train_y = train['comment'], train['label']\n",
    "    tmp = data.iloc[test_index]\n",
    "\n",
    "    val, test = train_test_split(tmp, test_size=0.5, stratify=tmp['label'])    \n",
    "    val_x, val_y = val['comment'], val['label']\n",
    "    test_x, test_y = test['comment'], test['label']    \n",
    "    \n",
    "    train_x = vectorizer(np.array([[s] for s in train_x])).numpy()    \n",
    "    val_x = vectorizer(np.array([[s] for s in val_x])).numpy()\n",
    "    test_x = vectorizer(np.array([[s] for s in test_x])).numpy()\n",
    "\n",
    "    train_x = keras.preprocessing.sequence.pad_sequences(train_x, maxlen=maxlen)\n",
    "    val_x = keras.preprocessing.sequence.pad_sequences(val_x, maxlen=maxlen)\n",
    "    test_x = keras.preprocessing.sequence.pad_sequences(test_x, maxlen=maxlen)\n",
    "    \n",
    "\n",
    "    inputs = layers.Input(shape=(maxlen,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, emb_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(emb_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model_path = \"transformer_models/{itr:04}\".format(itr=cnt)\n",
    "    checkpoint_path = model_path + \"-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    !mkdir $model_path\n",
    "    \n",
    "    model.compile(tf.keras.optimizers.Adam(lr=0.001), \"binary_crossentropy\", metrics=[\"accuracy\", \n",
    "                                                                                       tf.keras.metrics.AUC(name='auc')])\n",
    "    \n",
    "  \n",
    "\n",
    "    model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_auc', verbose=1,\n",
    "            save_weights_only=True, save_best_only=True, mode='max')\n",
    "    \n",
    "    history = model.fit(\n",
    "                        train_x, train_y, \n",
    "                        batch_size=128, epochs=10, \n",
    "                        validation_data=(val_x, val_y),\n",
    "                        callbacks = [checkpoint]\n",
    "                        )\n",
    "    \n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    model.load_weights(latest)\n",
    "    \n",
    "    train_eval = model.evaluate(train_x, train_y)\n",
    "    val_eval = model.evaluate(val_x, val_y)\n",
    "    test_eval = model.evaluate(test_x, test_y)\n",
    "    \n",
    "    test_l.append(test_eval)\n",
    "    val_l.append(val_eval)\n",
    "    train_l.append(train_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-29T03:04:34.559115Z",
     "iopub.status.busy": "2021-08-29T03:04:34.555969Z",
     "iopub.status.idle": "2021-08-29T03:04:34.564572Z",
     "shell.execute_reply": "2021-08-29T03:04:34.563851Z",
     "shell.execute_reply.started": "2021-08-28T22:10:16.365619Z"
    },
    "papermill": {
     "duration": 1.811035,
     "end_time": "2021-08-29T03:04:34.564673",
     "exception": false,
     "start_time": "2021-08-29T03:04:32.753638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.5033192992210388 +/- 0.053803696558922504\n",
      "test avg acc:  0.8430000066757202 +/- 0.0169705514812273\n",
      "test avg auc:  0.9093926787376404 +/- 0.005195930486075064\n",
      "\n",
      "\n",
      "val avg loss:  0.533100688457489 +/- 0.08111285570773213\n",
      "val avg acc:  0.8296000003814697 +/- 0.01593234897204257\n",
      "val avg auc:  0.9027897119522095 +/- 0.006370408285382021\n",
      "\n",
      "\n",
      "train avg loss:  0.013208652881439775 +/- 0.009509810056984563\n",
      "train avg acc:  0.9971750020980835 +/- 0.0020133997831377035\n",
      "train avg auc:  0.9998472929000854 +/- 0.00014589189660493327\n"
     ]
    }
   ],
   "source": [
    "test_l = np.array(test_l)\n",
    "val_l = np.array(val_l)\n",
    "train_l = np.array(train_l)\n",
    "\n",
    "print(\"test avg loss: \", np.mean(test_l[:, 0]), \"+/-\" ,np.std(test_l[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(test_l[:, 1]),  \"+/-\" ,np.std(test_l[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(test_l[:, 2]),  \"+/-\" ,np.std(test_l[:, 2]))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"val avg loss: \", np.mean(val_l[:, 0]), \"+/-\" ,np.std(val_l[:, 0]))\n",
    "print(\"val avg acc: \", np.mean(val_l[:, 1]),  \"+/-\" ,np.std(val_l[:, 1]))\n",
    "print(\"val avg auc: \", np.mean(val_l[:, 2]),  \"+/-\" ,np.std(val_l[:, 2]))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"train avg loss: \", np.mean(train_l[:, 0]), \"+/-\" ,np.std(train_l[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(train_l[:, 1]),  \"+/-\" ,np.std(train_l[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(train_l[:, 2]),  \"+/-\" ,np.std(train_l[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 17206.333522,
   "end_time": "2021-08-29T03:04:36.537702",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-28T22:17:50.204180",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
